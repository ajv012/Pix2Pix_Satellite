# -*- coding: utf-8 -*-
"""Pix2Pix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tiwOG8GOOd63u686IIbXd7LwjY8bJ2Ty
"""

# some imports

# numpy
from numpy import asarray, vstack, savez_compressed, load, zeros, ones 
from numpy.random import randint

#keras
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from keras.optimizers import Adam
from keras.initializers import RandomNormal
from keras.models import Model
from keras.models import Input
from keras.layers import Conv2D
from keras.layers import Conv2DTranspose
from keras.layers import LeakyReLU
from keras.layers import Activation
from keras.layers import Concatenate
from keras.layers import Dropout
from keras.layers import BatchNormalization
from keras.layers import LeakyReLU

# others
from matplotlib import pyplot
from os import listdir

print('Done with imports')

# mount gdrive
from google.colab import drive
drive.mount('/content/drive', force_remount = True)

# function to load images
def load_images(path, size=(256,512)):
  # define source and target arrays
  src_list, tar_list = list(), list()

  # enumerate files in directory (images only)
  for filename in listdir(path):

    # load the image and resize it 
    img = load_img(path + filename, target_size=size)
    
    # convert image to np array 
    img = img_to_array(img)

    # img is satellite and map, so split it up 
    sat_image, map_image = img[:,:256], img[:,256:]

    # store sat and map images
    src_list.append(sat_image)
    tar_list.append(map_image)

  # eventually return array version of src and tar lists 
  return[asarray(src_list), asarray(tar_list)]

# training dataset directory 
root_train = "drive/My Drive/GANs/maps/train/"
[src_images, tar_images] = load_images(root_train)
print("Loaded source images: " + str(src_images.shape) + " and target images: " + str(tar_images.shape))

# for later use, save as a compressed folder. Can access later using numpy load() function
filename = "maps_256.npz"
savez_compressed(filename, src_images, tar_images)
print("saved dataset: " + filename)

# plot some images to see if correctly loaded
data = load("maps_256.npz")
src_images, tar_images = data["arr_0"], data["arr_1"]
print("Loaded data: ", src_images.shape, tar_images.shape)

# plot num src and tar images 
num = 3
for i in range(num):
  pyplot.subplot(2, num, i + 1)
  pyplot.axis("off")
  pyplot.imshow(src_images[i].astype("uint8"))

for i in range(num):
  pyplot.subplot(2, num, i + 1 + num)
  pyplot.axis("off")
  pyplot.imshow(tar_images[i].astype("uint8"))

# define the discriminator model 
def define_discriminator(image_shape):

  # Prepare images for network
  # randomly initialize weights
  init = RandomNormal(stddev=0.02)
  # source input image 
  in_src_image = Input(shape=image_shape)
  # target input image 
  in_target_image = Input(shape=image_shape)
  # concatenate images channel wise 
  merged = Concatenate()([in_src_image, in_target_image])

  # define model

  # convolution 64 + leaky relu
  d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)
  # leaky relu fixes the dying gradient problem (number in brackets shows slope when x<0)
  d = LeakyReLU(alpha=0.2)(d)

  # convolution 128 + batchnorm + leaky relu
  d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
  d = BatchNormalization()(d)
  d = LeakyReLU(alpha=0.2)(d)

  # convolution 256 + batchnorm + leaky relu
  d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
  d = BatchNormalization()(d)
  d = LeakyReLU(alpha=0.2)(d)

  # convolution 512 + batchnorm + leaky relu
  d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)
  d = BatchNormalization()(d)
  d = LeakyReLU(alpha=0.2)(d)

  # convolution again + batchnorm + leaky relu
  d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)
  d = BatchNormalization()(d)
  d = LeakyReLU(alpha=0.2)(d)
 
  # patch output 
  d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)
  patch_out = Activation('sigmoid')(d)

  # define model
  model = Model([in_src_image, in_target_image], patch_out)
 
  # compile model
  opt = Adam(lr=0.0002, beta_1=0.5)
  model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])
  return model

# define helper methods to generate generator model 

# generate encoder blocks
def define_encoder_block(layer_in, n_filters, batchnorm=True):
  # initialize weights for the layer
  init = RandomNormal(stddev=0.02)

  # first downsampling layer
  g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)
  
  # conditionally add batch normalization
  if batchnorm:
    g = BatchNormalization()(g, training=True)
	
  # leaky relu activation
  g = LeakyReLU(alpha=0.2)(g)
  return g

# generate decoder blocks 
def decoder_block(layer_in, skip_in, n_filters, dropout=True):

  # weight initialization
  init = RandomNormal(stddev=0.02)

  # add upsampling layer
  g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)

  # add batch normalization
  g = BatchNormalization()(g, training=True)

  # conditionally add dropout
  if dropout:
    g = Dropout(0.5)(g, training=True)

  # merge with skip connection
  g = Concatenate()([g, skip_in])

  # relu activation
  g = Activation('relu')(g)
  return g

# define the standalone generator model
def define_generator(image_shape=(256,256,3)):
	# weight initialization
	init = RandomNormal(stddev=0.02)
	# image input
	in_image = Input(shape=image_shape)
	# encoder model
	e1 = define_encoder_block(in_image, 64, batchnorm=False)
	e2 = define_encoder_block(e1, 128)
	e3 = define_encoder_block(e2, 256)
	e4 = define_encoder_block(e3, 512)
	e5 = define_encoder_block(e4, 512)
	e6 = define_encoder_block(e5, 512)
	e7 = define_encoder_block(e6, 512)
	# bottleneck, no batch norm and relu
	b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)
	b = Activation('relu')(b)
	# decoder model
	d1 = decoder_block(b, e7, 512)
	d2 = decoder_block(d1, e6, 512)
	d3 = decoder_block(d2, e5, 512)
	d4 = decoder_block(d3, e4, 512, dropout=False)
	d5 = decoder_block(d4, e3, 256, dropout=False)
	d6 = decoder_block(d5, e2, 128, dropout=False)
	d7 = decoder_block(d6, e1, 64, dropout=False)
	# output
	g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)
	out_image = Activation('tanh')(g)
	# define model
	model = Model(in_image, out_image)
	return model

def define_gan(g_model, d_model, image_shape):
  # make weights in the discriminator not trainable
  d_model.trainable = False
  # define the source image
  in_src = Input(shape=image_shape)
  # connect the source image to the generator input
  gen_out = g_model(in_src)
  # connect the source input and generator output to the discriminator input
  dis_out = d_model([in_src, gen_out])
  # src image as input, generated image and classification output
  model = Model(in_src, [dis_out, gen_out])
  # compile model
  opt = Adam(lr=0.0002, beta_1=0.5)
  model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])
  return model

def load_real_samples(filename):
  # load compressed arrays
  data = load(filename)
  # unpack arrays
  X1, X2 = data['arr_0'], data['arr_1']
  # scale from [0,255] to [-1,1]
  X1 = (X1 - 127.5) / 127.5
  X2 = (X2 - 127.5) / 127.5
  return [X1, X2]

# select a batch of random samples, returns images and target
def generate_real_samples(dataset, n_samples, patch_shape):
	# unpack dataset
	trainA, trainB = dataset
	# choose random instances
	ix = randint(0, trainA.shape[0], n_samples)
	# retrieve selected images
	X1, X2 = trainA[ix], trainB[ix]
	# generate 'real' class labels (1)
	y = ones((n_samples, patch_shape, patch_shape, 1))
	return [X1, X2], y

# generate a batch of images, returns images and targets
def generate_fake_samples(g_model, samples, patch_shape):
	# generate fake instance
	X = g_model.predict(samples)
	# create 'fake' class labels (0)
	y = zeros((len(X), patch_shape, patch_shape, 1))
	return X, y

# generate samples and save as a plot and save the model
def summarize_performance(step, g_model, dataset, n_samples=3):
	# select a sample of input images
	[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)
	# generate a batch of fake samples
	X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)
	# scale all pixels from [-1,1] to [0,1]
	X_realA = (X_realA + 1) / 2.0
	X_realB = (X_realB + 1) / 2.0
	X_fakeB = (X_fakeB + 1) / 2.0
	# plot real source images
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + i)
		pyplot.axis('off')
		pyplot.imshow(X_realA[i])
	# plot generated target image
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + n_samples + i)
		pyplot.axis('off')
		pyplot.imshow(X_fakeB[i].astype("float64"))
	# plot real target image
	for i in range(n_samples):
		pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)
		pyplot.axis('off')
		pyplot.imshow(X_realB[i].astype("float64"))
	# save plot to file
	pyplot.show()
	filename1 = 'plot_%06d.png' % (step+1)
	pyplot.savefig(filename1)
	pyplot.close()
	# save the generator model
	filename2 = 'model_%06d.h5' % (step+1)
	g_model.save(filename2)
	print('>Saved: %s and %s' % (filename1, filename2))

# train pix2pix model
def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):
  # determine the output square shape of the discriminator
  n_patch = d_model.output_shape[1]
  # unpack dataset
  trainA, trainB = dataset
  # calculate the number of batches per training epoch
  bat_per_epo = int(len(trainA) / n_batch)
  # calculate the number of training iterations
  n_steps = bat_per_epo * n_epochs
  # manually enumerate epochs

  for i in range(n_steps):
    # select a batch of real samples
    [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)
    # generate a batch of fake samples
    X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)
    # update discriminator for real samples
    d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)
    # update discriminator for generated samples
    d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)
    # update the generator
    g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])
    # summarize performance
    print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))
  
    # summarize model performance
    if (i+1) % (1000) == 0:
      print("---------------------------------")
      summarize_performance(i, g_model, dataset)
      print("---------------------------------")

# load image data
dataset = load_real_samples('maps_256.npz')
print('Loaded', dataset[0].shape, dataset[1].shape)
# define input shape based on the loaded dataset
image_shape = dataset[0].shape[1:]
# define the models
d_model = define_discriminator(image_shape)
g_model = define_generator(image_shape)
# define the composite model
gan_model = define_gan(g_model, d_model, image_shape)
# train model
train(d_model, g_model, gan_model, dataset)
